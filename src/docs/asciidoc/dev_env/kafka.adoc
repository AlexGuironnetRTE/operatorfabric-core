// Copyright (c) 2018-2020 RTE (http://www.rte-france.com)
// See AUTHORS.txt
// This document is subject to the terms of the Creative Commons Attribution 4.0 International license.
// If a copy of the license was not distributed with this
// file, You can obtain one at https://creativecommons.org/licenses/by/4.0/.
// SPDX-License-Identifier: CC-BY-4.0

:kafka_schema: https://docs.confluent.io/current/schema-registry/index.html
:confluent: https://www.confluent.io/
:spring_kafka_doc: https://docs.spring.io/spring-kafka/reference/html/

= Kafka Implementation

Next to publishing cards to OperatorFabric using the REST API, OperatorFabric also supports publishing cards via a Kafka Topic. In the default configuration Kafka is disabled.


== Enabling Kafka

To enable Kafka support you need to set the `kafka.consumer.group_id property` in the cards-publication yml file:
[source,yaml]
----
  kafka:
    consumer:
      group-id: opfab-command
----

Alternatively you can set the group id in the `config/docker/kafka-env.properties` file:
[source, shell]
----
SPRING_KAFKA_CONSUMER_GROUP_ID=opfab-command
----

Make sure you also set the registry to either an empty string (`""`) or to the server providing the schema registry service. See link:{kafka_schema}[Schema management].

== OperatorFabric Kafka source code
== Listener / deserializer
Most of the OperatorFabric Kafka implementation can be found at `org.lfenergy.operatorfabric.cards.publication.kafka` and `org.lfenergy.operatorfabric.autoconfigure.kafka`.

=== Kafka OperatorFabric AVRO schema
The AVRO schema, the byte format in which messages are transffered using Kafka topics, can be found at `client/src/main/avro`. Message are sent to topics using the CardCommand object.
This object is an almost one-to-one mapping of the OperatorFabric card, see also <<card_structure>>. The exceptions are  `Process` and
`Process Instance Identifier`, which are moved to the top-level CardCommand.


== Configure Kafka
=== Setting a new deserializer
By default, OperatorFabric uses the  `io.confluent.kafka.serializers.KafkaAvroDeserializer` from link:{confluent}[Confluent]. However, you can write your own
deserializer. An example deserializer, which ignores the schema registry, is included. See `org.lfenergy.operatorfabric.cards.publication.kafka.consumer.KafkaAvroWithoutRegistryDeserializer`.

== Kafka card producer
To send a CardCommand to OperatorFabric, start by implementing a simple Kafka producer by following for example link:{spring_kafka_doc}[Spring for Apache Kafka]
Note that some properties of CardCommand or its embedded Card are required. If not set, the card will be rejected by OperatorFabric.

When you dump the card to stdout, you should see something like the line below. Do ignore the actual values.

[source, json]
----
{
  "command": "CREATE_CARD",
  "process": "integrationTest",
  "processInstanceId": "c7b1ac61-192b-11eb-b2f5-eea952defe56",
  "card": {
    "parentCardUid": null,
    "publisher": "myFirstPublisher",
    "processVersion": "2",
    "state": "FirstUserTask",
    "publishDate": null,
    "lttd": null,
    "startDate": 1603896139000,
    "endDate": 1604068947000,
    "severity": "ALARM",
    "tags": null,
    "timeSpans": null,
    "details": null,
    "title": {
      "key": "FirstUserTask.title",
      "parameters": null
    },
    "summary": {
      "key": "FirstUserTask.summary",
      "parameters": null
    },
    "recipient": null,
    "userRecipients": [
      "tso1-operator",
      "tso2-operator"
    ],
    "groupRecipients": null,
    "externalRecipients": null,
    "entitiesAllowedToRespond": [
      "ENTITY1"
    ],
    "entityRecipients": null,
    "hasBeenAcknowledged": null,
    "data": "{\"action\":\"Just do something\"}"
  }
}
----

== Response Cards
OperatorFabric <<response_cards>> are currently returned only via REST. At the time of writing it is not possible to return
response cards via Kafka.
